"""
Alzheimer’s Disease Diagnosis – Multimodal Dual‑Agent (SAC) Framework
---------------------------------------------------------------------

This file provides a reference/experimental implementation for a framework inspired by the paper:
"Alzheimer’s disease diagnosis using large language model and multi‑modality data: An approach based on soft actor‑critic".

The code is modular and contains these main parts:

1) Dataset loading & preprocessing (MRI image + clinical text)
2) Feature extraction (VGG for MRI, Transformer embeddings for text)
3) Two bridging autoencoders trained adversarially (GAN) to translate MRI ↔ Text
4) Agent‑1: Soft Actor‑Critic (SAC) for Active Learning (decide label vs. skip)
5) Agent‑2: SAC‑driven Feature Selection + Classification with LIME‑based rewards
6) Hyper‑parameter search with Random‑Key + Mutual‑Learning Artificial Bee Colony (ML‑ABC)
7) End‑to‑End pipeline & evaluation (ACC/F1/TPR/AUC)

Notes:
- This is a research template. You must adapt paths, hyper‑parameters, and training loops to your hardware/data.
- Use the `--demo` flag for a lightweight/quick run.

Python 3.10+
Requires: PyTorch, torchvision, transformers, scikit‑learn, pandas, numpy, pillow, lime
"""
from __future__ import annotations

import os
import sys
import json
import math
import time
import copy
import random
import argparse
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.preprocessing import StandardScaler

try:
    from PIL import Image
except Exception as e:
    raise e

# Optional: use transformers for text embeddings if available
_HAS_TRANSFORMERS = False
try:
    from transformers import AutoTokenizer, AutoModel
    _HAS_TRANSFORMERS = True
except Exception:
    pass

# Optional: LIME for feature importance/reward
_HAS_LIME = False
try:
    from lime.lime_tabular import LimeTabularExplainer
    _HAS_LIME = True
except Exception:
    pass

# Optional: torchvision VGG16 as MRI feature extractor
_HAS_TORCHVISION = False
try:
    import torchvision
    from torchvision import transforms
    from torchvision.models import vgg16, VGG16_Weights
    _HAS_TORCHVISION = True
except Exception:
    pass


# -----------------------------
# Utils & Config
# -----------------------------

def set_seed(seed: int = 42) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)


def get_device() -> torch.device:
    return torch.device("cuda" if torch.cuda.is_available() else "cpu")


@dataclass
class Paths:
    data_csv: str = "./data/dataset.csv"  # columns: image_path, text, label
    image_root: str = "./data/images"
    cache_dir: str = "./cache"


@dataclass
class HyperParams:
    # General
    seed: int = 42
    batch_size: int = 64
    epochs_gan: int = 10
    epochs_cls: int = 10
    lr: float = 1e-3
    dropout: float = 0.3

    # SAC
    sac_gamma: float = 0.99
    sac_tau: float = 0.005
    sac_alpha: float = 0.2  # used if auto‑alpha is disabled
    sac_auto_alpha: bool = True
    sac_target_entropy: Optional[float] = None  # if None, set automatically for discrete actions
    sac_buffer_size: int = 20000
    sac_batch: int = 128
    sac_lr: float = 3e-4

    # Feature dimensions
    mri_feat_dim: int = 512  # pooled VGG output
    txt_feat_dim: int = 384  # e.g., all‑MiniLM‑L6‑v2
    shared_latent: int = 256

    # GAN
    gan_hidden: int = 512
    gan_topk_suppress: int = 4  # Top‑K suppression during G update

    # Final classifier
    clf_hidden: int = 256

    # Active Learning
    al_budget: int = 100
    al_entropy_eta_start: float = 0.2
    al_entropy_eta_end: float = 0.6

    # ML‑ABC
    abc_iters: int = 10
    abc_pop: int = 8
    abc_F: float = 0.5  # mutual learning coefficient
    abc_patience: int = 5


# -----------------------------
# Dataset & Feature Extractors
# -----------------------------
class MRITextPairDataset(Dataset):
    """Dataset reading image path + raw text + label from a CSV.

    Required CSV columns: image_path, text, label (0/1)
    """

    def __init__(self, csv_file: str, image_root: str, transform: Optional[Any] = None):
        super().__init__()
        self.df = pd.read_csv(csv_file)
        if not all(c in self.df.columns for c in ["image_path", "text", "label"]):
            raise ValueError("CSV must contain columns: image_path, text, label")
        self.image_root = image_root
        self.transform = transform

    def __len__(self) -> int:
        return len(self.df)

    def __getitem__(self, idx: int) -> Dict[str, Any]:
        row = self.df.iloc[idx]
        img_path = os.path.join(self.image_root, str(row["image_path"]))
        text = str(row["text"]) if not pd.isna(row["text"]) else ""
        label = int(row["label"]) if not pd.isna(row["label"]) else -1

        img = Image.open(img_path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)

        return {"image": img, "text": text, "label": label}


class VGGFeatureExtractor(nn.Module):
    """Pretrained VGG16 backbone to extract 512‑d features per image.
    Uses adaptive avg pooling to obtain a single vector.
    """

    def __init__(self, device: torch.device):
        super().__init__()
        if not _HAS_TORCHVISION:
            raise ImportError("torchvision is required for VGGFeatureExtractor")
        weights = VGG16_Weights.DEFAULT
        base = vgg16(weights=weights)
        self.features = base.features
        self.pool = nn.AdaptiveAvgPool2d((1, 1))
        self.to(device)
        for p in self.parameters():
            p.requires_grad = False

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        feat = self.features(x)
        feat = self.pool(feat)
        feat = torch.flatten(feat, 1)
        return feat  # [B, 512]


class TextEmbedder(nn.Module):
    """Text embedding wrapper. If `transformers` is not available, falls back to a simple hashed BoW projection.
    Returns a fixed‑size vector (txt_feat_dim).
    """

    def __init__(self, device: torch.device, model_name: str = "sentence-transformers/all-MiniLM-L6-v2", out_dim: int = 384):
        super().__init__()
        self.device = device
        self.out_dim = out_dim
        self.mode = "hf" if _HAS_TRANSFORMERS else "hash"
        if self.mode == "hf":
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name).to(device)
            self.model.eval()
        else:
            # Simple: fixed random projection for hashed BoW counts
            self.register_buffer("proj", torch.randn(1024, out_dim) * 0.01)

    @torch.no_grad()
    def forward(self, texts: List[str]) -> torch.Tensor:
        if self.mode == "hf":
            toks = self.tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors="pt").to(self.device)
            out = self.model(**toks)
            # mean pooling
            emb = out.last_hidden_state.mean(dim=1)  # [B, H]
            if emb.shape[1] != self.out_dim:
                # light linear projection when dims differ
                W = torch.eye(emb.shape[1], device=self.device)[: self.out_dim]
                emb = emb @ W.T
            return emb
        else:
            # hash‑based simple embedding
            vecs = []
            for t in texts:
                h = np.zeros(1024, dtype=np.float32)
                for w in t.split():
                    idx = hash(w) % 1024
                    h[idx] += 1.0
                vecs.append(h)
            H = torch.tensor(np.stack(vecs), device=self.device)
            return H @ self.proj  # [B, out_dim]


# -----------------------------
# Bridging Autoencoders + GAN (with Top‑K gradient suppression)
# -----------------------------
class MLPBlock(nn.Module):
    def __init__(self, d_in: int, d_out: int, p_drop: float = 0.0, act: str = "relu"):
        super().__init__()
        self.fc = nn.Linear(d_in, d_out)
        self.bn = nn.BatchNorm1d(d_out)
        self.drop = nn.Dropout(p_drop)
        self.act = nn.ReLU() if act.lower() == "relu" else (
            nn.LeakyReLU(0.1) if act.lower() == "leaky relu" else (
                nn.Tanh() if act.lower() == "tanh" else nn.Sigmoid()
            )
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.drop(self.act(self.bn(self.fc(x))))


class AutoencoderGenerator(nn.Module):
    def __init__(self, in_dim: int, out_dim: int, latent: int, hidden: int, dropout: float, act: str = "ReLU"):
        super().__init__()
        self.encoder = nn.Sequential(
            MLPBlock(in_dim, hidden, dropout, act),
            MLPBlock(hidden, latent, dropout, act),
        )
        self.decoder = nn.Sequential(
            MLPBlock(latent, hidden, dropout, act),
            nn.Linear(hidden, out_dim),
        )

    def encode(self, x: torch.Tensor) -> torch.Tensor:
        return self.encoder(x)

    def decode(self, z: torch.Tensor) -> torch.Tensor:
        return self.decoder(z)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        z = self.encode(x)
        y = self.decode(z)
        return y


class Discriminator(nn.Module):
    def __init__(self, in_dim: int, hidden: int, dropout: float, act: str = "ReLU"):
        super().__init__()
        self.net = nn.Sequential(
            MLPBlock(in_dim, hidden, dropout, act),
            nn.Linear(hidden, 1),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


class BridgingGAN(nn.Module):
    """Adversarially trained autoencoder (generator) with Top‑K gradient suppression.
    Maps from src_dim -> tgt_dim.
    """

    def __init__(self, src_dim: int, tgt_dim: int, latent: int, hidden: int, dropout: float, topk: int, lr: float = 1e-3, act: str = "ReLU"):
        super().__init__()
        self.G = AutoencoderGenerator(src_dim, tgt_dim, latent, hidden, dropout, act)
        self.D = Discriminator(tgt_dim, hidden, dropout, act)
        self.topk = topk
        self.opt_G = torch.optim.Adam(self.G.parameters(), lr=lr)
        self.opt_D = torch.optim.Adam(self.D.parameters(), lr=lr)

    def g_step(self, x_src: torch.Tensor, real_tgt: torch.Tensor) -> Dict[str, float]:
        self.opt_G.zero_grad()
        fake_tgt = self.G(x_src)
        d_scores = torch.sigmoid(self.D(fake_tgt.detach())).view(-1)
        # Compute reconstruction + adversarial losses
        recon_loss = F.mse_loss(fake_tgt, real_tgt)
        adv_loss = F.binary_cross_entropy_with_logits(self.D(fake_tgt), torch.ones_like(d_scores))
        g_loss = recon_loss + 0.1 * adv_loss

        # Backprop with gradient retention for masking
        g_loss.backward(retain_graph=True)

        # Top‑K suppression: zero out gradients contributed by the K easiest samples
        with torch.no_grad():
            k = min(self.topk, d_scores.numel())
            topk_idx = torch.topk(d_scores, k=k, largest=True).indices
        for p in self.G.parameters():
            if p.grad is None:
                continue
            # Heuristic: if first dim equals batch, mask those entries
            if p.grad.ndim >= 2 and p.grad.shape[0] == d_scores.shape[0]:
                mask = torch.ones_like(p.grad)
                mask[topk_idx] = 0.0
                p.grad.mul_(mask)

        self.opt_G.step()
        return {"g_recon": float(recon_loss.detach().cpu()), "g_adv": float(adv_loss.detach().cpu())}

    def d_step(self, real_tgt: torch.Tensor, x_src: torch.Tensor) -> Dict[str, float]:
        self.opt_D.zero_grad()
        with torch.no_grad():
            fake_tgt = self.G(x_src)
        real_logit = self.D(real_tgt)
        fake_logit = self.D(fake_tgt)
        d_real = F.binary_cross_entropy_with_logits(real_logit, torch.ones_like(real_logit))
        d_fake = F.binary_cross_entropy_with_logits(fake_logit, torch.zeros_like(fake_logit))
        d_loss = d_real + d_fake
        d_loss.backward()
        self.opt_D.step()
        return {"d_loss": float(d_loss.detach().cpu())}

    @torch.no_grad()
    def translate(self, x_src: torch.Tensor) -> torch.Tensor:
        return self.G(x_src)


# -----------------------------
# Discrete SAC (policy + Qs) + Replay Buffer
# -----------------------------
class ReplayBuffer:
    def __init__(self, capacity: int):
        self.capacity = capacity
        self.ptr = 0
        self.full = False
        self.S = None
        self.A = None
        self.R = None
        self.SN = None
        self.D = None

    def _init(self, s: torch.Tensor, a: torch.Tensor, r: torch.Tensor, sn: torch.Tensor, d: torch.Tensor):
        n, ds = s.shape
        self.S = torch.zeros((self.capacity, ds), dtype=torch.float32)
        self.A = torch.zeros((self.capacity,), dtype=torch.long)
        self.R = torch.zeros((self.capacity,), dtype=torch.float32)
        self.SN = torch.zeros((self.capacity, ds), dtype=torch.float32)
        self.D = torch.zeros((self.capacity,), dtype=torch.float32)

    def add(self, s: torch.Tensor, a: torch.Tensor, r: torch.Tensor, sn: torch.Tensor, d: torch.Tensor):
        if self.S is None:
            self._init(s, a, r, sn, d)
        n = s.shape[0]
        for i in range(n):
            self.S[self.ptr] = s[i].cpu()
            self.A[self.ptr] = int(a[i].cpu())
            self.R[self.ptr] = float(r[i].cpu())
            self.SN[self.ptr] = sn[i].cpu()
            self.D[self.ptr] = float(d[i].cpu())
            self.ptr = (self.ptr + 1) % self.capacity
            if self.ptr == 0:
                self.full = True

    def sample(self, batch: int) -> Tuple[torch.Tensor, ...]:
        maxn = self.capacity if self.full else self.ptr
        idx = np.random.randint(0, maxn, size=(batch,))
        return (
            torch.tensor(self.S[idx], dtype=torch.float32),
            torch.tensor(self.A[idx], dtype=torch.long),
            torch.tensor(self.R[idx], dtype=torch.float32),
            torch.tensor(self.SN[idx], dtype=torch.float32),
            torch.tensor(self.D[idx], dtype=torch.float32),
        )


class PolicyNet(nn.Module):
    def __init__(self, s_dim: int, a_dim: int, hidden: int = 256, dropout: float = 0.1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(s_dim, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, a_dim)
        )

    def forward(self, s: torch.Tensor) -> torch.Tensor:
        logits = self.net(s)
        return logits  # [B, A]


class QNet(nn.Module):
    def __init__(self, s_dim: int, a_dim: int, hidden: int = 256, dropout: float = 0.1):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(s_dim, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, a_dim)
        )

    def forward(self, s: torch.Tensor) -> torch.Tensor:
        return self.net(s)


class DiscreteSAC:
    """SAC implementation for discrete action spaces (categorical policy)."""

    def __init__(self, s_dim: int, a_dim: int, hp: HyperParams, device: torch.device):
        self.device = device
        self.hp = hp
        self.a_dim = a_dim

        self.policy = PolicyNet(s_dim, a_dim, hp.clf_hidden, hp.dropout).to(device)
        self.q1 = QNet(s_dim, a_dim, hp.clf_hidden, hp.dropout).to(device)
        self.q2 = QNet(s_dim, a_dim, hp.clf_hidden, hp.dropout).to(device)
        self.q1_t = copy.deepcopy(self.q1).to(device)
        self.q2_t = copy.deepcopy(self.q2).to(device)

        self.opt_p = torch.optim.Adam(self.policy.parameters(), lr=hp.sac_lr)
        self.opt_q1 = torch.optim.Adam(self.q1.parameters(), lr=hp.sac_lr)
        self.opt_q2 = torch.optim.Adam(self.q2.parameters(), lr=hp.sac_lr)

        if hp.sac_auto_alpha:
            self.log_alpha = torch.tensor(math.log(hp.sac_alpha), requires_grad=True, device=device)
            self.opt_alpha = torch.optim.Adam([self.log_alpha], lr=hp.sac_lr)
        else:
            self.log_alpha = torch.tensor(math.log(hp.sac_alpha), requires_grad=False, device=device)

        self.target_entropy = -math.log(1.0 / a_dim) if hp.sac_target_entropy is None else hp.sac_target_entropy
        self.buf = ReplayBuffer(hp.sac_buffer_size)

    @property
    def alpha(self) -> torch.Tensor:
        return self.log_alpha.exp()

    def select_action(self, s: torch.Tensor, explore: bool = True) -> torch.Tensor:
        s = s.to(self.device)
        logits = self.policy(s)
        probs = F.softmax(logits, dim=-1)
        if explore:
            dist = torch.distributions.Categorical(probs=probs)
            a = dist.sample()
        else:
            a = probs.argmax(dim=-1)
        return a

    def update(self, batch: int) -> Dict[str, float]:
        if self.buf.S is None or (self.buf.ptr < batch and not self.buf.full):
            return {}
        S, A, R, SN, D = self.buf.sample(batch)
        S = S.to(self.device)
        A = A.to(self.device)
        R = R.to(self.device)
        SN = SN.to(self.device)
        D = D.to(self.device)

        # --- targets ---
        with torch.no_grad():
            logits_n = self.policy(SN)
            logp_n = F.log_softmax(logits_n, dim=-1)
            p_n = logp_n.exp()
            q1n = self.q1_t(SN)
            q2n = self.q2_t(SN)
            qn = torch.min(q1n, q2n)
            v_n = (p_n * (qn - self.alpha * logp_n)).sum(dim=-1)
            y = R + (1.0 - D) * self.hp.sac_gamma * v_n

        # --- update Qs ---
        q1 = self.q1(S).gather(1, A.view(-1, 1)).squeeze(1)
        q2 = self.q2(S).gather(1, A.view(-1, 1)).squeeze(1)
        q1_loss = F.mse_loss(q1, y.detach())
        q2_loss = F.mse_loss(q2, y.detach())
        self.opt_q1.zero_grad(); q1_loss.backward(); self.opt_q1.step()
        self.opt_q2.zero_grad(); q2_loss.backward(); self.opt_q2.step()

        # --- update policy ---
        logits = self.policy(S)
        logp = F.log_softmax(logits, dim=-1)
        p = logp.exp()
        q1_pi = self.q1(S)
        q2_pi = self.q2(S)
        q_pi = torch.min(q1_pi, q2_pi)
        p_loss = (p * (self.alpha.detach() * logp - q_pi)).sum(dim=-1).mean()
        self.opt_p.zero_grad(); p_loss.backward(); self.opt_p.step()

        # --- update alpha ---
        alpha_loss_val = 0.0
        if self.hp.sac_auto_alpha:
            alpha_loss = -(self.log_alpha * (logp + self.target_entropy).detach()).sum(dim=-1).mean()
            self.opt_alpha.zero_grad(); alpha_loss.backward(); self.opt_alpha.step()
            alpha_loss_val = float(alpha_loss.detach().cpu())

        # --- soft target updates ---
        with torch.no_grad():
            for tp, p in zip(self.q1_t.parameters(), self.q1.parameters()):
                tp.data.mul_(1 - self.hp.sac_tau).add_(self.hp.sac_tau * p.data)
            for tp, p in zip(self.q2_t.parameters(), self.q2.parameters()):
                tp.data.mul_(1 - self.hp.sac_tau).add_(self.hp.sac_tau * p.data)

        return {
            "q1": float(q1_loss.detach().cpu()),
            "q2": float(q2_loss.detach().cpu()),
            "p": float(p_loss.detach().cpu()),
            "alpha": float(self.alpha.detach().cpu()),
            "alpha_loss": alpha_loss_val,
        }


# -----------------------------
# Classification Network (on fused tabular features)
# -----------------------------
class Classifier(nn.Module):
    def __init__(self, in_dim: int, hidden: int, dropout: float):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_dim, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout),
            nn.Linear(hidden, 2)
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


# -----------------------------
# Agent‑2: Feature Selection + Classification with LIME‑based reward
# -----------------------------
class FSDetectionEnv:
    """Episodic environment for feature selection and final classification.
    State: concatenation of feature vector (z) and binary mask (m)
    Actions: [0..F-1] (select a feature) + classification action (F)
    Reward: LIME‑based gain for selection, weighted correctness at classification step
    """

    def __init__(self, clf: Classifier, lime_explainer: Optional[LimeTabularExplainer], minority_weight: float = 2.0):
        self.clf = clf
        self.explainer = lime_explainer
        self.minority_weight = minority_weight

    def reset(self, z: torch.Tensor, y: int) -> Dict[str, Any]:
        self.z = z.detach().clone()  # [F]
        self.y = int(y)
        self.Fdim = z.numel()
        self.m = torch.zeros(self.Fdim, dtype=torch.float32)  # feature mask
        return self._state()

    def _state(self) -> torch.Tensor:
        return torch.cat([self.z, self.m], dim=0)  # [2F]

    def step(self, action: int) -> Tuple[torch.Tensor, float, bool, Dict[str, Any]]:
        done = False
        info: Dict[str, Any] = {}
        if action < self.Fdim:
            # add a feature
            self.m[action] = 1.0
            # LIME gain for this selection
            lime_gain = 0.0
            if self.explainer is not None:
                try:
                    inp = (self.z * self.m).detach().cpu().numpy()
                    def _pred_fn(xx: np.ndarray) -> np.ndarray:
                        with torch.no_grad():
                            t = torch.tensor(xx, dtype=torch.float32)
                            out = self.clf(t).softmax(-1).cpu().numpy()
                        return out
                    exp = self.explainer.explain_instance(inp, _pred_fn, num_features=min(10, self.Fdim))
                    # Build approximate importance vector
                    w = np.zeros(self.Fdim)
                    for idx, val in exp.as_list():
                        try:
                            j = int(str(idx).replace('x', ''))
                        except Exception:
                            j = int(idx) if isinstance(idx, int) else None
                        if j is not None and 0 <= j < self.Fdim:
                            w[j] = val
                    lime_gain = float(w[action])
                except Exception:
                    lime_gain = 0.0
            reward = float(lime_gain)
            return self._state(), reward, done, info
        else:
            # terminate with classification
            with torch.no_grad():
                logits = self.clf((self.z * self.m).unsqueeze(0))
                pred = int(logits.argmax(dim=-1).item())
            correct = float(pred == self.y)
            weight = self.minority_weight if self.y == 1 else 1.0
            reward = weight * (1.0 if correct > 0 else -1.0)
            done = True
            return self._state(), float(reward), done, {"pred": pred}


class ClassificationAgent:
    def __init__(self, in_dim: int, hp: HyperParams, device: torch.device, lime_explainer: Optional[LimeTabularExplainer] = None):
        self.device = device
        self.hp = hp
        self.clf = Classifier(in_dim, hp.clf_hidden, hp.dropout).to(device)
        self.env = FSDetectionEnv(self.clf, lime_explainer, minority_weight=2.0)
        self.sac = DiscreteSAC(s_dim=in_dim * 2, a_dim=in_dim + 1, hp=hp, device=device)
        self.opt_clf = torch.optim.Adam(self.clf.parameters(), lr=hp.lr)

    def supervised_step(self, feats: torch.Tensor, labels: torch.Tensor) -> Dict[str, float]:
        self.clf.train()
        logits = self.clf(feats)
        loss = F.cross_entropy(logits, labels)
        self.opt_clf.zero_grad(); loss.backward(); self.opt_clf.step()
        with torch.no_grad():
            pred = logits.argmax(dim=-1)
            acc = (pred == labels).float().mean().item()
        return {"sup_loss": float(loss.detach().cpu()), "sup_acc": float(acc)}

    def rl_episode(self, z: torch.Tensor, y: int, max_steps: int = 32) -> Dict[str, Any]:
        s = self.env.reset(z, y)
        s = s.to(self.device)
        total_r = 0.0
        for t in range(max_steps):
            a = self.sac.select_action(s.unsqueeze(0), explore=True)
            s_next, r, done, info = self.env.step(int(a.item()))
            s_next = s_next.to(self.device)
            total_r += r
            self.sac.buf.add(s.unsqueeze(0), a.view(1), torch.tensor([r], dtype=torch.float32), s_next.unsqueeze(0), torch.tensor([float(done)], dtype=torch.float32))
            _ = self.sac.update(self.hp.sac_batch)
            s = s_next
            if done:
                break
        return {"episode_return": total_r}

    @torch.no_grad()
    def predict(self, feats: torch.Tensor) -> torch.Tensor:
        self.clf.eval()
        return self.clf(feats).softmax(dim=-1)


# -----------------------------
# Agent‑1: Active Learning (label vs skip) with entropy‑threshold reward
# -----------------------------
class ActiveLearningAgent:
    def __init__(self, in_dim: int, hp: HyperParams, device: torch.device):
        self.device = device
        self.hp = hp
        # State = [fused features | model confidence]
        self.s_dim = in_dim + 1
        self.sac = DiscreteSAC(s_dim=self.s_dim, a_dim=2, hp=hp, device=device)
        self.eta = hp.al_entropy_eta_start

    def _entropy(self, probs: torch.Tensor) -> torch.Tensor:
        p = probs.clamp_min(1e-8)
        return -(p * p.log()).sum(dim=-1)

    def _update_eta(self, progress: float) -> None:
        # Linearly increase entropy threshold as training progresses
        self.eta = self.hp.al_entropy_eta_start + (self.hp.al_entropy_eta_end - self.hp.al_entropy_eta_start) * float(np.clip(progress, 0.0, 1.0))

    def decide(self, features: torch.Tensor, conf: torch.Tensor, progress: float) -> Tuple[int, float]:
        # features: [D], conf: scalar in [0,1]
        self._update_eta(progress)
        s = torch.cat([features, conf.view(1)], dim=0).unsqueeze(0).to(self.device)
        a = self.sac.select_action(s, explore=True)
        return int(a.item()), float(self.eta)

    def step(self, 
             features: torch.Tensor, 
             probs: torch.Tensor, 
             action: int, 
             eta_used: float) -> Dict[str, float]:
        # Reward based on entropy rule: encourage skipping when confident, otherwise query
        ent = self._entropy(probs.unsqueeze(0))[0].item()
        if action == 1:  # choose to label
            reward = -0.05  # labeling cost
            done = 0.0
        else:  # skip
            reward = 1.0 if ent < eta_used else -1.0
            done = 1.0  # terminal for this sample

        s = torch.cat([features, probs.max().view(1)], dim=0).unsqueeze(0)
        self.sac.buf.add(s, torch.tensor([action]), torch.tensor([reward], dtype=torch.float32), s, torch.tensor([done], dtype=torch.float32))
        _ = self.sac.update(self.hp.sac_batch)
        return {"al_reward": reward, "entropy": ent}


# -----------------------------
# Hyperparameter Optimization: Random‑Key + ML‑ABC
# -----------------------------
@dataclass
class RKSpace:
    # map of name -> (type, options or (low, high))
    space: Dict[str, Any] = field(default_factory=dict)

    def encode_random(self) -> Dict[str, Any]:
        cfg = {}
        for k, v in self.space.items():
            if v[0] == "cont":
                lo, hi = v[1]
                cfg[k] = float(np.random.uniform(lo, hi))
            elif v[0] == "int":
                lo, hi = v[1]
                cfg[k] = int(np.random.randint(lo, hi + 1))
            elif v[0] == "cat":
                opts = v[1]
                cfg[k] = random.choice(opts)
            else:
                raise ValueError("unknown type")
        return cfg


class MLABC:
    def __init__(self, rk: RKSpace, fitness_fn, hp: HyperParams):
        self.rk = rk
        self.fitness_fn = fitness_fn
        self.hp = hp

    def optimize(self, iters: int, pop: int) -> Tuple[Dict[str, Any], float]:
        pop_cfg = [self.rk.encode_random() for _ in range(pop)]
        pop_fit = [self.fitness_fn(c) for c in pop_cfg]
        best_idx = int(np.argmax(pop_fit))
        best_cfg = pop_cfg[best_idx]
        best_fit = float(pop_fit[best_idx])
        no_improve = 0
        for it in range(iters):
            new_cfg = []
            new_fit = []
            for i in range(pop):
                j = np.random.randint(0, pop)
                while j == i:
                    j = np.random.randint(0, pop)
                ci = copy.deepcopy(pop_cfg[i])
                cj = pop_cfg[j]
                # Mutual learning: move towards a better neighbor
                if pop_fit[j] > pop_fit[i]:
                    alpha = np.random.uniform(0, self.hp.abc_F)
                else:
                    alpha = np.random.uniform(0, 0.1)
                cand = {}
                for k in ci:
                    vi, vj = ci[k], cj[k]
                    if isinstance(vi, (int, float)) and isinstance(vj, (int, float)):
                        cand[k] = type(vi)(vi + alpha * (vj - vi))
                    else:
                        cand[k] = random.choice([vi, vj])
                new_cfg.append(cand)
                new_fit.append(self.fitness_fn(cand))
            # Selection
            for i in range(pop):
                if new_fit[i] > pop_fit[i]:
                    pop_cfg[i] = new_cfg[i]
                    pop_fit[i] = new_fit[i]
            bidx = int(np.argmax(pop_fit))
            if pop_fit[bidx] > best_fit:
                best_fit = float(pop_fit[bidx])
                best_cfg = pop_cfg[bidx]
                no_improve = 0
            else:
                no_improve += 1
            if no_improve >= self.hp.abc_patience:
                break
        return best_cfg, best_fit


# -----------------------------
# End‑to‑End Framework
# -----------------------------
class MainFramework:
    def __init__(self, paths: Paths, hp: HyperParams, demo: bool = False):
        set_seed(hp.seed)
        self.device = get_device()
        self.paths = paths
        self.hp = hp
        self.demo = demo

        # Image transforms for MRI
        if _HAS_TORCHVISION:
            self.tx = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
        else:
            self.tx = None

        os.makedirs(paths.cache_dir, exist_ok=True)

        # Dataset loader
        self.dataset = MRITextPairDataset(paths.data_csv, paths.image_root, transform=self.tx)
        # Train/Val/Test split
        idx = list(range(len(self.dataset)))
        y_all = [int(self.dataset.df.iloc[i]["label"]) for i in idx]
        id_train, id_tmp = train_test_split(idx, test_size=0.3, stratify=y_all, random_state=hp.seed)
        id_val, id_test = train_test_split(id_tmp, test_size=0.5, stratify=[y_all[i] for i in id_tmp], random_state=hp.seed)
        self.splits = {"train": id_train, "val": id_val, "test": id_test}

        # Feature extractors
        self.vgg = VGGFeatureExtractor(self.device) if _HAS_TORCHVISION else None
        self.txt = TextEmbedder(self.device, out_dim=hp.txt_feat_dim)

        # Dimensions
        self.mri_dim = hp.mri_feat_dim
        self.txt_dim = hp.txt_feat_dim
        self.fused_dim = self.mri_dim + self.txt_dim

        # Bridging networks
        self.mri2txt = BridgingGAN(self.mri_dim, self.txt_dim, hp.shared_latent, hp.gan_hidden, hp.dropout, topk=hp.gan_topk_suppress, lr=hp.lr)
        self.txt2mri = BridgingGAN(self.txt_dim, self.mri_dim, hp.shared_latent, hp.gan_hidden, hp.dropout, topk=hp.gan_topk_suppress, lr=hp.lr)

        # LIME (dummy background; replace with your dataset sample matrix for better fidelity)
        self.lime = LimeTabularExplainer(np.zeros((10, self.fused_dim), dtype=np.float32), discretize_continuous=False) if _HAS_LIME else None

        # Agents
        self.agent2 = ClassificationAgent(in_dim=self.fused_dim, hp=hp, device=self.device, lime_explainer=self.lime)
        self.agent1 = ActiveLearningAgent(in_dim=self.fused_dim, hp=hp, device=self.device)

        # Feature cache per split: id -> (mri_feat, txt_feat, label)
        self.cache_feats: Dict[str, Dict[int, Tuple[np.ndarray, np.ndarray, int]]] = {"train": {}, "val": {}, "test": {}}

    @torch.no_grad()
    def _extract_features_batch(self, batch: List[int]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        imgs = []
        texts = []
        ys = []
        for i in batch:
            item = self.dataset[i]
            imgs.append(item["image"])  # [3,224,224]
            texts.append(item["text"])
            ys.append(int(item["label"]))
        imgs_t = torch.stack(imgs).to(self.device) if len(imgs) > 0 else torch.empty(0)
        if self.vgg is None:
            # Fallback when torchvision is unavailable: stable random features
            mri_feat = torch.randn((len(batch), self.mri_dim), device=self.device)
        else:
            mri_feat = self.vgg(imgs_t)
            # Map to target dimension if needed
            if mri_feat.shape[1] != self.mri_dim:
                mri_feat = nn.Linear(mri_feat.shape[1], self.mri_dim, bias=False).to(self.device)(mri_feat)
        txt_feat = self.txt(texts)
        return mri_feat, txt_feat, torch.tensor(ys, dtype=torch.long, device=self.device)

    def _prepare_cache(self) -> None:
        """Extract and cache features for all splits for fast iteration."""
        for split, ids in self.splits.items():
            for i in ids:
                mri, txt, y = self._extract_features_batch([i])
                self.cache_feats[split][i] = (
                    mri[0].detach().cpu().numpy(),
                    txt[0].detach().cpu().numpy(),
                    int(y.item()),
                )

    def _get_batch_feats(self, split: str, batch_ids: List[int]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        mri, txt, y = [], [], []
        for i in batch_ids:
            fm, ft, fy = self.cache_feats[split][i]
            mri.append(fm)
            txt.append(ft)
            y.append(fy)
        mri_t = torch.tensor(np.stack(mri), dtype=torch.float32, device=self.device)
        txt_t = torch.tensor(np.stack(txt), dtype=torch.float32, device=self.device)
        y_t = torch.tensor(np.array(y), dtype=torch.long, device=self.device)
        return mri_t, txt_t, y_t

    def train_bridging(self) -> None:
        """Train both GAN‑AEs for MRI→Text and Text→MRI."""
        for epoch in range(self.hp.epochs_gan):
            random.shuffle(self.splits["train"])
            batches = [self.splits["train"][i:i+self.hp.batch_size] for i in range(0, len(self.splits["train"]), self.hp.batch_size)]
            log = []
            for bid in batches:
                mri, txt, _ = self._get_batch_feats("train", bid)
                # mri->txt
                g1 = self.mri2txt.g_step(mri, txt)
                d1 = self.mri2txt.d_step(txt, mri)
                # txt->mri
                g2 = self.txt2mri.g_step(txt, mri)
                d2 = self.txt2mri.d_step(mri, txt)
                log.append({**{f"m2t_{k}": v for k, v in g1.items()}, **d1, **{f"t2m_{k}": v for k, v in g2.items()}, **{f"d2_{k}": v for k, v in d2.items()}})
            if (epoch + 1) % max(1, self.hp.epochs_gan // 5) == 0:
                avg = {k: float(np.mean([x[k] for x in log])) for k in log[0].keys()}
                print(f"[GAN] epoch {epoch+1}: {json.dumps(avg)}")

    def fused_features(self, mri: torch.Tensor, txt: torch.Tensor) -> torch.Tensor:
        """Fuse MRI and text features; if one modality is missing, translate via bridging GAN."""
        if mri is None and txt is None:
            raise ValueError("Both modalities missing")
        if mri is None:
            with torch.no_grad():
                mri = self.txt2mri.translate(txt)
        if txt is None:
            with torch.no_grad():
                txt = self.mri2txt.translate(mri)
        return torch.cat([mri, txt], dim=-1)

    def train_classifier_supervised(self, epochs: int = 5) -> None:
        """Warm‑up supervised training for the classifier (Agent‑2 backbone)."""
        for ep in range(epochs):
            random.shuffle(self.splits["train"])
            batches = [self.splits["train"][i:i+self.hp.batch_size] for i in range(0, len(self.splits["train"]), self.hp.batch_size)]
            log = []
            for bid in batches:
                mri, txt, y = self._get_batch_feats("train", bid)
                z = self.fused_features(mri, txt)
                log.append(self.agent2.supervised_step(z, y))
            if (ep + 1) % max(1, epochs // 5) == 0:
                avg = {k: float(np.mean([x[k] for x in log])) for k in log[0].keys()}
                print(f"[CLS-SUP] epoch {ep+1}: {json.dumps(avg)}")

    def active_learning_cycle(self, budget: int) -> None:
        """Run one AL budget cycle on unlabeled pool; if none provided, use validation split as a proxy."""
        unlabeled = [i for i in self.splits["train"] if self.dataset.df.iloc[i]["label"] == -1]
        if len(unlabeled) == 0:
            unlabeled = self.splits["val"][:]
        random.shuffle(unlabeled)
        used = 0
        for t, i in enumerate(unlabeled):
            if used >= budget:
                break
            fm, ft, _ = self.cache_feats["val"][i]
            mri = torch.tensor(fm, dtype=torch.float32, device=self.device).unsqueeze(0)
            txt = torch.tensor(ft, dtype=torch.float32, device=self.device).unsqueeze(0)
            z = self.fused_features(mri, txt)
            with torch.no_grad():
                probs = self.agent2.predict(z)[0]  # [2]
                conf = probs.max()
            a, eta = self.agent1.decide(z[0], conf, progress=t/ max(1, budget-1))
            stats = self.agent1.step(z[0].detach(), probs.detach(), a, eta)
            # If labeled, pseudo‑label and move to train split (for demonstration)
            if a == 1:
                pseudo = int(probs.argmax().item())
                self.cache_feats["train"][i] = (fm, ft, pseudo)
                self.splits["train"].append(i)
                used += 1
            if (t + 1) % 20 == 0:
                print(f"[AL] step {t+1}/{len(unlabeled)}: {stats}")

    def rl_fsdetection_train(self, episodes: int = 100) -> None:
        """Reinforcement learning episodes for feature selection + detection (Agent‑2)."""
        train_ids = self.splits["train"]
        for ep in range(episodes):
            i = random.choice(train_ids)
            fm, ft, fy = self.cache_feats["train"][i]
            mri = torch.tensor(fm, dtype=torch.float32, device=self.device)
            txt = torch.tensor(ft, dtype=torch.float32, device=self.device)
            z = self.fused_features(mri.unsqueeze(0), txt.unsqueeze(0))[0]
            _ = self.agent2.rl_episode(z, fy)
            if (ep + 1) % max(1, episodes // 5) == 0:
                print(f"[FS-DET] episode {ep+1}/{episodes}")

    @torch.no_grad()
    def evaluate(self, split: str = "test") -> Dict[str, float]:
        ids = self.splits[split]
        Y, P, S = [], [], []
        for i in ids:
            fm, ft, fy = self.cache_feats[split][i]
            mri = torch.tensor(fm, dtype=torch.float32, device=self.device).unsqueeze(0)
            txt = torch.tensor(ft, dtype=torch.float32, device=self.device).unsqueeze(0)
            z = self.fused_features(mri, txt)
            probs = self.agent2.predict(z)[0].cpu().numpy()
            Y.append(int(fy))
            P.append(int(np.argmax(probs)))
            S.append(float(probs[1]))
        acc = accuracy_score(Y, P)
        f1 = f1_score(Y, P)
        try:
            auc = roc_auc_score(Y, S)
        except Exception:
            auc = float('nan')
        tn, fp, fn, tp = confusion_matrix(Y, P).ravel()
        tpr = tp / max(1, tp + fn)
        return {"ACC": float(acc), "F1": float(f1), "TPR": float(tpr), "AUC": float(auc)}

    def fitness_quick(self, cfg: Dict[str, Any]) -> float:
        """Lightweight fitness for ML‑ABC: tweak a few hparams and return validation F1."""
        old_lr = self.hp.lr
        self.hp.lr = float(np.clip(cfg.get("lr", self.hp.lr), 1e-5, 1e-2))
        self.agent2.opt_clf = torch.optim.Adam(self.agent2.clf.parameters(), lr=self.hp.lr)
        self.train_classifier_supervised(epochs=1 if self.demo else 2)
        score = self.evaluate("val")["F1"]
        self.hp.lr = old_lr
        self.agent2.opt_clf = torch.optim.Adam(self.agent2.clf.parameters(), lr=self.hp.lr)
        return float(score)

    def run(self) -> None:
        print("[Stage] Preparing cache features...")
        self._prepare_cache()
        print("[Stage] Training bridging AEs (GAN)...")
        self.train_bridging()
        print("[Stage] Warm-up supervised classifier...")
        self.train_classifier_supervised(epochs=2 if self.demo else self.hp.epochs_cls)
        print("[Stage] Active Learning cycle...")
        self.active_learning_cycle(budget=10 if self.demo else self.hp.al_budget)
        print("[Stage] RL-based FS+Detection training...")
        self.rl_fsdetection_train(episodes=20 if self.demo else 100)
        print("[Stage] Hyperparameter search (ML-ABC)...")
        rk = RKSpace(space={
            "lr": ("cont", (1e-4, 5e-3)),
        })
        abc = MLABC(rk, self.fitness_quick, self.hp)
        best_cfg, best_fit = abc.optimize(iters=2 if self.demo else self.hp.abc_iters, pop=4 if self.demo else self.hp.abc_pop)
        print(f"[ABC] best={best_cfg}, fit={best_fit:.4f}")
        print("[Stage] Final evaluation on test set...")
        final = self.evaluate("test")
        print(json.dumps(final, ensure_ascii=False))


# -----------------------------
# CLI
# -----------------------------

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--csv", type=str, default="./data/dataset.csv")
    parser.add_argument("--images", type=str, default="./data/images")
    parser.add_argument("--cache", type=str, default="./cache")
    parser.add_argument("--demo", action="store_true", help="Lightweight quick run")
    args = parser.parse_args()

    paths = Paths(data_csv=args.csv, image_root=args.images, cache_dir=args.cache)
    hp = HyperParams()

    fw = MainFramework(paths, hp, demo=args.demo)
    fw.run()


if __name__ == "__main__":
    main()

